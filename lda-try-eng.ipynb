{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is latent dirichlet allocation program. I use this program for my learning purpose.\n",
    "\n",
    "Thanks to Alfan Farizki Wicaksono from Fasilkom, Universitas Indonesia.\n",
    "Actually this is Alfan's code, so I'm just copying his code from Pusilkom UI website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models import ldamodel\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define function for load our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    file = open(filename, 'r')\n",
    "\n",
    "    acc_names = []\n",
    "    tweets = []\n",
    "\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        parts = line.split('###')\n",
    "        acc_names.append(parts[0])\n",
    "        tweets.append(parts[1])\n",
    "\n",
    "    return acc_names, tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define number of topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config variables\n",
    "num_topics=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definisikan beberapa fungsi untuk kebutuhkan pre-processing, pre-processing yang dilakukan adalah\n",
    "# 1. lowercasing\n",
    "# 2. stopword removal\n",
    "# 3. stemming\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "\n",
    "    # tokenizing and lowercasing\n",
    "    tokens = [word.lower() for word in text.split()]\n",
    "    filtered_tokens = []\n",
    "\n",
    "    # buat yang bukan terdiri dari alfabet, dan merupakan stopword\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token) and (token not in stopwords):\n",
    "            filtered_tokens.append(token)\n",
    "\n",
    "    # lakukan stemming dengan snowball stemmer\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can import our dataset. I got the dataset from Alfan. Regarding to his statement in his website, he get the dataset from twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kita load dokumen twitter, dan lakukan preprocessing terhadap tweet yang sudah di-load\n",
    "acc_names, tweets = load_dataset(\"twitter.txt\")\n",
    "\n",
    "# Lakukan pre-process untuk setiap tweet pada koleksi \"tweets\" kita\n",
    "# Gunakan List Comprehension untuk mempermudah hidup kita\n",
    "tweets = [preprocess(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['kardashian',\n",
       "  'yr',\n",
       "  'anniversary,',\n",
       "  'iphon',\n",
       "  'yr',\n",
       "  'anniversary,',\n",
       "  'so,',\n",
       "  'kardashian',\n",
       "  'made',\n",
       "  'iphon'],\n",
       " ['iphon',\n",
       "  'year',\n",
       "  'old.',\n",
       "  'appl',\n",
       "  'watch',\n",
       "  'year',\n",
       "  'old.',\n",
       "  'feel',\n",
       "  'peopl',\n",
       "  'forget',\n",
       "  'small',\n",
       "  'fact.'],\n",
       " [\"can't\",\n",
       "  'save',\n",
       "  'make,',\n",
       "  'live',\n",
       "  'beyond',\n",
       "  'means.',\n",
       "  'ditch',\n",
       "  'starbucks,',\n",
       "  'eat',\n",
       "  'less,',\n",
       "  'need',\n",
       "  'new',\n",
       "  'iphone,',\n",
       "  'save',\n",
       "  'money!'],\n",
       " ['time', 'year!', 'iphon', 'vs.', 'samsung', 'galaxi', 's8', 'smackdown:'],\n",
       " ['sell',\n",
       "  'yeezi',\n",
       "  'samsung',\n",
       "  'galaxi',\n",
       "  's8',\n",
       "  'anyon',\n",
       "  'interest',\n",
       "  'show',\n",
       "  'proof',\n",
       "  'trust',\n",
       "  '@devilishrt',\n",
       "  '@alienrt',\n",
       "  '@bear_retweet',\n",
       "  '@flyrt'],\n",
       " ['iphon',\n",
       "  '16gb',\n",
       "  'spacegray',\n",
       "  'peso',\n",
       "  'only!',\n",
       "  'complet',\n",
       "  'full',\n",
       "  'packag',\n",
       "  'guys!',\n",
       "  'dm'],\n",
       " ['swear',\n",
       "  'even',\n",
       "  'iphon',\n",
       "  'dress',\n",
       "  'clown,',\n",
       "  'reach',\n",
       "  'pillow',\n",
       "  '&choke',\n",
       "  'slept,',\n",
       "  'still',\n",
       "  'buy',\n",
       "  'samsung'],\n",
       " ['iphon',\n",
       "  '8',\n",
       "  'a11',\n",
       "  'bionic',\n",
       "  'chip',\n",
       "  'lost',\n",
       "  'samsung',\n",
       "  'galaxi',\n",
       "  'note',\n",
       "  'app',\n",
       "  'launch',\n",
       "  'time',\n",
       "  'multitask',\n",
       "  'speeds.'],\n",
       " ['confus',\n",
       "  'post',\n",
       "  'dedic',\n",
       "  'camera',\n",
       "  'review',\n",
       "  'samsung',\n",
       "  'galaxi',\n",
       "  'note',\n",
       "  'includ',\n",
       "  'camera',\n",
       "  'section',\n",
       "  'main',\n",
       "  'full',\n",
       "  'review?'],\n",
       " ['guy', 'use', 'iphone6&', 'samsung', 'galaxi', 'sale..', 'plz', 'dm'],\n",
       " ['mom', 'say', 'devil', 'give', 'samsung,', 'take', 'iphon', 'return?'],\n",
       " ['cassi', 'iphon', 'could', 'open', 'lie', 'face!', '#60min'],\n",
       " ['infam',\n",
       "  'samsung',\n",
       "  'galaxi',\n",
       "  'note',\n",
       "  'still',\n",
       "  'ban',\n",
       "  'aircraft',\n",
       "  'even',\n",
       "  'got',\n",
       "  'prohibit',\n",
       "  'symbol'],\n",
       " ['so,',\n",
       "  'realli',\n",
       "  'dumb',\n",
       "  'phone.',\n",
       "  'samsung',\n",
       "  'galaxi',\n",
       "  'note',\n",
       "  'phone',\n",
       "  'great',\n",
       "  'mayb',\n",
       "  'year',\n",
       "  'ago,'],\n",
       " ['\"bro',\n",
       "  'window',\n",
       "  'delux',\n",
       "  'brick',\n",
       "  'trashcan',\n",
       "  'everyth',\n",
       "  'iphon',\n",
       "  'sheep',\n",
       "  'bro\"'],\n",
       " ['samsung',\n",
       "  'galaxi',\n",
       "  'note',\n",
       "  'camera:',\n",
       "  'blur',\n",
       "  'line',\n",
       "  'samsung',\n",
       "  'attempt',\n",
       "  'redempt',\n",
       "  'note',\n",
       "  'line',\n",
       "  'is,',\n",
       "  'part,'],\n",
       " ['iphon', 'x', 'look', 'lot', 'like', 'samsung', 'galaxi', 's10', 'plus'],\n",
       " ['congratulations.',\n",
       "  'news',\n",
       "  'iphon',\n",
       "  'jailbreak',\n",
       "  'bought',\n",
       "  'new',\n",
       "  'iphone.'],\n",
       " ['messi',\n",
       "  'arguabl',\n",
       "  'greatest',\n",
       "  'perform',\n",
       "  'major',\n",
       "  'final',\n",
       "  'champion',\n",
       "  'leagu',\n",
       "  'final)',\n",
       "  'ever.'],\n",
       " ['im',\n",
       "  'gonna',\n",
       "  'boo',\n",
       "  'gini',\n",
       "  'tomorrow,',\n",
       "  'alway',\n",
       "  'gonna',\n",
       "  'leav',\n",
       "  'man,',\n",
       "  'good',\n",
       "  'championship',\n",
       "  'champion',\n",
       "  'leagu',\n",
       "  'tabl',\n",
       "  'ffs...'],\n",
       " ['grayson',\n",
       "  'backtracking,',\n",
       "  'lost',\n",
       "  'me,',\n",
       "  'bruce',\n",
       "  'same.',\n",
       "  'mcgeadi',\n",
       "  'wrongun',\n",
       "  'celebration,',\n",
       "  'thought',\n",
       "  \"we'd\",\n",
       "  'champion',\n",
       "  'league,p!ss',\n",
       "  'poor',\n",
       "  '#safc'],\n",
       " ['chelsea', 'found', 'citi', 'atletico', 'madrid'],\n",
       " ['delph',\n",
       "  'idiot',\n",
       "  'leav',\n",
       "  'villa.',\n",
       "  'releg',\n",
       "  'battl',\n",
       "  'first',\n",
       "  'choic',\n",
       "  'player',\n",
       "  'champion',\n",
       "  'leagu',\n",
       "  'prem'],\n",
       " ['chelsea', 'taken', 'point', 'possibl', 'champion', 'leagu', 'fixtur'],\n",
       " ['zinedin',\n",
       "  'zidane:',\n",
       "  '\"give',\n",
       "  'lord',\n",
       "  'fellaini',\n",
       "  'piec',\n",
       "  'wood',\n",
       "  \"i'll\",\n",
       "  'win',\n",
       "  'champion',\n",
       "  'league,',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'uefa',\n",
       "  'euro'],\n",
       " ['dj', 'play', 'champion', 'leagu', 'anthem', 'chic', 'caught', 'bouquet'],\n",
       " ['harri',\n",
       "  'kane',\n",
       "  'current',\n",
       "  'joint',\n",
       "  'top',\n",
       "  'scorer',\n",
       "  'premier',\n",
       "  'leagu',\n",
       "  'outright',\n",
       "  'top',\n",
       "  'scorer',\n",
       "  'champion',\n",
       "  'league.',\n",
       "  'elite.'],\n",
       " ['harri',\n",
       "  'kane',\n",
       "  'one',\n",
       "  'deserv',\n",
       "  'world-class',\n",
       "  'tag',\n",
       "  'despit',\n",
       "  'cut',\n",
       "  'intern',\n",
       "  'tournament',\n",
       "  'champion',\n",
       "  'leagu',\n",
       "  '(yet).'],\n",
       " ['christensen:',\n",
       "  'face',\n",
       "  'striker',\n",
       "  'bundesliga',\n",
       "  'two',\n",
       "  'year',\n",
       "  'champion',\n",
       "  'leagu',\n",
       "  'well,',\n",
       "  'got',\n",
       "  'much',\n",
       "  'experience.',\n",
       "  '[telegraph]'],\n",
       " ['sinc',\n",
       "  'premier',\n",
       "  'leagu',\n",
       "  'club',\n",
       "  'domin',\n",
       "  'champion',\n",
       "  'leagu',\n",
       "  'like',\n",
       "  'this.'],\n",
       " ['good',\n",
       "  'luck',\n",
       "  'arsenal',\n",
       "  'europa',\n",
       "  'leagu',\n",
       "  'game,',\n",
       "  'hope',\n",
       "  'next',\n",
       "  'season',\n",
       "  'get',\n",
       "  'play',\n",
       "  'champion',\n",
       "  'league.'],\n",
       " ['chelsea',\n",
       "  'display',\n",
       "  'best',\n",
       "  'english',\n",
       "  'club',\n",
       "  'champion',\n",
       "  'leagu',\n",
       "  'season.',\n",
       "  'win',\n",
       "  'away',\n",
       "  'atletico',\n",
       "  'mean',\n",
       "  'feat.',\n",
       "  'full',\n",
       "  'valu',\n",
       "  'too.'],\n",
       " ['brilliant',\n",
       "  'scottish',\n",
       "  'crew',\n",
       "  'support',\n",
       "  'catalan',\n",
       "  'referendum,',\n",
       "  'viva',\n",
       "  'catalunya'],\n",
       " ['brexit',\n",
       "  'support',\n",
       "  'support',\n",
       "  'catalunya',\n",
       "  'referendum',\n",
       "  'sovereignti',\n",
       "  'self',\n",
       "  'determin',\n",
       "  'nations.',\n",
       "  'si'],\n",
       " ['offici',\n",
       "  'referendum',\n",
       "  'day',\n",
       "  'babi',\n",
       "  'awooooo',\n",
       "  '(wolf',\n",
       "  'howl)',\n",
       "  'catalunya',\n",
       "  'ride'],\n",
       " ['derri',\n",
       "  'wall',\n",
       "  'turn',\n",
       "  'yellow',\n",
       "  'red',\n",
       "  'solidar',\n",
       "  'catalonia',\n",
       "  'eve',\n",
       "  'independ',\n",
       "  'referendum.',\n",
       "  'viva',\n",
       "  'catalunya!'],\n",
       " ['watch',\n",
       "  'madrid',\n",
       "  'forc',\n",
       "  'polic',\n",
       "  'catalunya',\n",
       "  'prevent',\n",
       "  'referendum',\n",
       "  'unedifi',\n",
       "  'spectacle.',\n",
       "  'whimper',\n",
       "  'liber',\n",
       "  'protest'],\n",
       " ['catalan',\n",
       "  'referendum',\n",
       "  'full',\n",
       "  'flow',\n",
       "  'barcelona',\n",
       "  'ever',\n",
       "  'happens,',\n",
       "  'peac',\n",
       "  'love,',\n",
       "  'right?'],\n",
       " ['patriot',\n",
       "  'fervour',\n",
       "  'barcelona',\n",
       "  'ahead',\n",
       "  'referendum',\n",
       "  'catalunya',\n",
       "  'tomorrow'],\n",
       " ['tomorrow',\n",
       "  '#indyref',\n",
       "  'referendum',\n",
       "  '#catalunya.',\n",
       "  'whole',\n",
       "  'europ',\n",
       "  'watch',\n",
       "  'close'],\n",
       " ['controversi',\n",
       "  'referendum',\n",
       "  'due',\n",
       "  'stage',\n",
       "  'sunday,',\n",
       "  'catalunya',\n",
       "  'seek',\n",
       "  'becom',\n",
       "  'recognis',\n",
       "  'nation'],\n",
       " ['last',\n",
       "  'poll',\n",
       "  'catalan',\n",
       "  'independ',\n",
       "  'referendum.83%',\n",
       "  'yes!',\n",
       "  'inform',\n",
       "  'ban',\n",
       "  'catalunya.'],\n",
       " ['catalan', 'judg', 'sue', 'spanish', 'govt.', 'block', 'referendum'],\n",
       " ['thought', 'tri', 'get', '@thenat', 'articl', 'catalunya', 'referendum'],\n",
       " ['wikileak',\n",
       "  'mirror',\n",
       "  'censor',\n",
       "  'catalan',\n",
       "  'govern',\n",
       "  'referendum',\n",
       "  'site',\n",
       "  'includ',\n",
       "  'poll',\n",
       "  'station'],\n",
       " ['chao',\n",
       "  'catalonia:',\n",
       "  'spanish',\n",
       "  'offici',\n",
       "  'scrambl',\n",
       "  'stop',\n",
       "  'secess',\n",
       "  'referendum'],\n",
       " ['tast', 'atmosfer', 'referendum', 'catalunya'],\n",
       " ['polic',\n",
       "  'chief',\n",
       "  'sent',\n",
       "  'stop',\n",
       "  'catalan',\n",
       "  'referendum,',\n",
       "  'fascist',\n",
       "  'support',\n",
       "  'tejero',\n",
       "  'coup'],\n",
       " ['@jaromil',\n",
       "  'ipf',\n",
       "  'block',\n",
       "  'catalunya',\n",
       "  'due',\n",
       "  'referendum,',\n",
       "  'necessari',\n",
       "  'collabor',\n",
       "  'main',\n",
       "  'providers.',\n",
       "  'mani',\n",
       "  'block',\n",
       "  'websites.'],\n",
       " ['this',\n",
       "  'manipul',\n",
       "  'spanish',\n",
       "  'knew',\n",
       "  'problem',\n",
       "  'catalunya',\n",
       "  'pp',\n",
       "  'el',\n",
       "  'care',\n",
       "  'referendum',\n",
       "  'valid',\n",
       "  'let',\n",
       "  'vote.ignor',\n",
       "  'el',\n",
       "  'pai']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dictionary for words in our document (in tweets variable). We will add unique words into this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat term dictionary dari korpus kita, dimana setiap kata unik akan diberikan sebuah index\n",
    "dictionary = Dictionary(tweets)\n",
    "\n",
    "# buang term yang:\n",
    "# pop term which:\n",
    "# 1. muncul di kurang dari 2 dokumen\n",
    "# 1. appears in less than 2 documents \n",
    "# 2. muncul di lebih dari 0.9*(total_dok) dokumen\n",
    "# 2. appears in more than  0.9*(total_doct) documents\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.9)\n",
    "\n",
    "# ubah dictionary menjadi object bag-of-words reference\n",
    "# ingat bahwa dalama LDA, dokumen diasumsikan dengan bag-of-words model\n",
    "corpus = [dictionary.doc2bow(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 2), (1, 1)],\n",
       " [(0, 1), (2, 1), (3, 2)],\n",
       " [(4, 1)],\n",
       " [(0, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(5, 1), (6, 1), (7, 1)],\n",
       " [(0, 1), (9, 1), (10, 1)],\n",
       " [(0, 1), (7, 1), (11, 1), (12, 1)],\n",
       " [(0, 1), (5, 1), (7, 1), (8, 1), (13, 1), (14, 1)],\n",
       " [(5, 1), (7, 1), (10, 1), (14, 1), (15, 1), (16, 1)],\n",
       " [(5, 1), (7, 1), (9, 1)],\n",
       " [(0, 1)],\n",
       " [(0, 1)],\n",
       " [(5, 1), (7, 1), (11, 1), (12, 1), (14, 1), (17, 1), (18, 1)],\n",
       " [(1, 1), (3, 1), (5, 1), (7, 1), (14, 1)],\n",
       " [(0, 1)],\n",
       " [(5, 1), (7, 2), (14, 2)],\n",
       " [(0, 1), (5, 1), (7, 1), (19, 1)],\n",
       " [(0, 1), (4, 1)],\n",
       " [(20, 1), (21, 1)],\n",
       " [(20, 1), (21, 1), (22, 1), (23, 1)],\n",
       " [(13, 1), (20, 1), (24, 1)],\n",
       " [(25, 1), (26, 1), (27, 1)],\n",
       " [(20, 1), (21, 1), (23, 1)],\n",
       " [(20, 1), (21, 1), (26, 1)],\n",
       " [(20, 1), (28, 1)],\n",
       " [(20, 1), (21, 1), (29, 1)],\n",
       " [(20, 1), (21, 1), (30, 1), (31, 1), (32, 1), (33, 1)],\n",
       " [(20, 1), (21, 1), (30, 1), (31, 1)],\n",
       " [(3, 1), (18, 1), (20, 1), (21, 1)],\n",
       " [(19, 1), (20, 1), (21, 2), (33, 1), (34, 1)],\n",
       " [(20, 1), (21, 1), (22, 1), (29, 1), (32, 1), (35, 1)],\n",
       " [(10, 1), (20, 1), (21, 1), (25, 1), (26, 1), (28, 1), (34, 1)],\n",
       " [(36, 1), (37, 1), (38, 1), (39, 1), (40, 1)],\n",
       " [(37, 1), (39, 2), (41, 1)],\n",
       " [(37, 1), (41, 1), (42, 1)],\n",
       " [(40, 1), (43, 1)],\n",
       " [(2, 1), (27, 1), (37, 1), (41, 1), (44, 1)],\n",
       " [(10, 1), (36, 1), (41, 1), (45, 1)],\n",
       " [(37, 1), (41, 1), (45, 1), (46, 1)],\n",
       " [(2, 1), (41, 1), (46, 1)],\n",
       " [(37, 1), (41, 1), (47, 1)],\n",
       " [(17, 1), (36, 1), (43, 1), (48, 1)],\n",
       " [(36, 1), (41, 1), (49, 1), (50, 1)],\n",
       " [(24, 1), (35, 1), (37, 1), (41, 1)],\n",
       " [(15, 1), (36, 1), (41, 1), (48, 1)],\n",
       " [(41, 1), (42, 1), (50, 1), (51, 1)],\n",
       " [(37, 1), (41, 1)],\n",
       " [(36, 1), (38, 1), (39, 1), (44, 1), (51, 1)],\n",
       " [(16, 1), (37, 1), (38, 1), (47, 1), (49, 2)],\n",
       " [(37, 1), (41, 1), (50, 1)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
